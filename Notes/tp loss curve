WITHOUT A SCHEDULER: the model reaches very low losses for the first 6 parameters very quickly. But the loss for TP is almost 5-10 times higher at the start as the others. It takes few epochs for the model to adapt its weights for TP, the loss values of other parameters goes up slightly. Later they all stabilize around similar loss values.

This is likely to be because TP values are really low before normalization. Their mean lies around e-06 and e-05. When normalizing these values, they get bigger and predicting the small differences becomes that much harder.

AT THE END WITH SCHEDULER: Average Test Loss at the End: 0.004283
Test Loss for T2M: 0.003414
Test Loss for U10: 0.003792
Test Loss for V10: 0.003974
Test Loss for Z: 0.008037
Test Loss for T: 0.003280
Test Loss for TCC: 0.003903
Test Loss for TP: 0.003582

Exponential Scheduler applied after 35 epochs with gamma 0.5 helps a lot to decrease the loss even more. The fluctuation behaviour is canceled and the loss goes down almost to 0.

For many to one models, the training hyperparameters are different from the many to many models. Many to one models seem to converge faster. With a learning rate of 10⁻³, the validation loss reaches a plateau after 6 epochs. A scheduler is applied starting with 6. epoch every 2 epochs with a gamma of 0.25. Validation loss after 20 epochs is computed for each parameter. Following Graph compares the per parameter validation losses of climatology and many-to-one models. (MAYBE TRY SCHEDULER AFTER 10. EPOCH with same gamma and frequency!)

T2M:  Validation Loss: 0.062774,   	Test Loss: 0.061871
U10:  Validation Loss: 0.241615,	Test Loss: 0.242670
V10:  Validation Loss: 0.275862,	Test Loss: 0.277890
Z:    Validation Loss: 0.054296,	Test Loss: 0.054547
T:    Validation Loss: 0.082200,	Test Loss: 0.082060
TCC:  Validation Loss: 0.491644,	Test Loss: 0.491097
TP:   Validation Loss:
