Given multi-variate time-varying dataset with ğ‘› âˆˆ N parameters and ğ‘‡ âˆˆ N timesteps, the user selects
the number ğ‘š of input fields from which the remaining n-m parameter fields are predicted.

A straight forward approach is to train only ğ‘› networks, where each network predicts one single parameter from the remaining ğ‘› âˆ’ 1 parameters, use the loss as an indicator of prediction difficulty.
The parameter predicted with the highest loss is fixed as one of the input parameters.
Then, of all trained networks where this parameter is already contained in the input set, the one with the largest loss is selected, and the variable that is predicted is added to the input.

But this approach ignores the prediction strength of smaller combination of parameters
ğ‘› networks are trained initially, with each network predicting one single parameter from the remaining ğ‘› âˆ’ 1 parameters, the parameter with the highest loss is fixed as the first input.
In the next iteration, all networks with ğ‘› âˆ’ 2 inputs (including the fixed parameter) and two outputs are trained.the overall loss is computed by adding the losses of all networks where this parameter is in the predicted set. The parameter with the highest loss is fixed as the next input, and so on.

All parameter fields are normalized before training.
If the dataset contains time-invariate parameters, such as spatially varying, but temporally constant orography descriptors, these fields are concatenated to the inputs to serve as additional information for the models. L1 loss is applied and model weights are optimized using standard backpropagation.

When comparing the loss curves in these early stages with the loss curves after convergence, the relative behaviour of the networks does not change. This indicates that the network training does not need to be performed until convergence, but can be stopped after a few epochs to obtain an indication.


NETWORK ARCHITECTURE:
A deep convolutional neural network (CNN) architecture to predict a certain number of output parameters from a given set of input parameters.

1- RESNET (Single spatial scale)
ResNet architecture with three residual blocks. Input size is (m x W x H).
Input block, a single convolution layer with (3,3) kernel, 64 channels, Batch normalization, LeakyReLU
Input padding before each convolution layer. Periodic padding in the longitude direction and replication padding elsewhere.

After that, three residual blocks. Each block has two convolution layers with 64 channels and kernel size (3,3). The residual blocks has this architecture: Conv--BN--Act--Conv--BN.
After each residual block there is a LeakyReLU activation.
Final layer is a single convolution layer with kernel size of (3,3) and n-m output channels.

2- UNET (Extraction of features on multiple spatial scales)
Two symmetric branches.
In the encoding branch, the data are encoded into an abstract reduced feature representation, and in the decoding path the feature representations are then decoded to reconstruct the predicted fields at the target resolution.
During the encoding step, the resolution is iteratively reduced, and the number of feature channels is increased at the same time. In the decoding step, while reducing the number of feature channels, the features are super-sampled to a higher resolution. The paths are connected by skip connections, which concatenate feature channels from the encoder with corresponding features from the decoder, in order to precisely preserve and localize the information in the data that could be lost in the encoding stage. The most bottom layer of the UNet, i.e., the bottleneck layer, enforces the model to learn a compact representation of the input containing the globally most relevant information to recover it.
Check the figure for the exact architecture.


